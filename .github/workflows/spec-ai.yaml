name: AI Spec-Assistant

on:
  pull_request:
    types: [opened, synchronize, labeled, unlabeled]
    paths:
      - "**/*.md"
      - "spec-templates/**"
      - "docs/specs/**"

env:
  PYTHON_VERSION: "3.11"

jobs:
  spec-ai-review:
    runs-on: ubuntu-latest
    if: contains(github.event.pull_request.labels.*.name, 'needs-spec-review')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Need full history for diff analysis

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install openai requests

      - name: Get PR diff
        id: diff
        run: |
          # Get the diff for this PR
          git fetch origin ${{ github.event.pull_request.base.sha }}
          git diff origin/${{ github.event.pull_request.base.sha }}...HEAD > pr_diff.txt

          # Extract markdown files from diff
          grep -E "^[+][+][+] b/.*\.md$" pr_diff.txt | sed 's/^[+][+][+] b\///' > changed_md_files.txt

          echo "Changed markdown files:"
          cat changed_md_files.txt || echo "No markdown files changed"

      - name: Run AI Spec Assistant
        id: ai-review
        run: |
          echo "Running AI Spec Assistant..."

          # Check if we have markdown changes
          if [ ! -s changed_md_files.txt ]; then
            echo "No markdown files changed, skipping AI review"
            echo "suggestions=[]" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Run the AI spec assistant
          python tools/specassistant/agent.py \
            --diff-file pr_diff.txt \
            --output suggestions.json \
            --api-key ${{ secrets.OPENAI_API_KEY }}

          # Check if suggestions were generated
          if [ -f suggestions.json ]; then
            echo "AI suggestions generated"
            cat suggestions.json
          else
            echo "No AI suggestions generated"
            echo "suggestions=[]" >> $GITHUB_OUTPUT
          fi

      - name: Post AI suggestions
        if: steps.ai-review.outputs.suggestions != '[]'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            // Read suggestions from file
            let suggestions = [];
            try {
              suggestions = JSON.parse(fs.readFileSync('suggestions.json', 'utf8'));
            } catch (e) {
              console.log('No suggestions file found');
            }

            if (suggestions.length === 0) {
              console.log('No suggestions to post');
              return;
            }

            // Format suggestions for GitHub comment
            let comment = '## AI Spec-Assistant Suggestions ü§ñ\n\n';

            // Group suggestions by type
            const byType = {};
            suggestions.forEach(suggestion => {
              if (!byType[suggestion.type]) {
                byType[suggestion.type] = [];
              }
              byType[suggestion.type].push(suggestion);
            });

            // Add suggestions by type
            Object.entries(byType).forEach(([type, typeSuggestions]) => {
              comment += `### ${type.charAt(0).toUpperCase() + type.slice(1)} Suggestions\n\n`;
              
              typeSuggestions.forEach(suggestion => {
                comment += `**${suggestion.content}**\n`;
                comment += `*Reasoning: ${suggestion.reasoning}*\n`;
                comment += `*Confidence: ${(suggestion.confidence * 100).toFixed(0)}%*\n\n`;
              });
            });

            comment += '---\n*Generated by AI Spec-Assistant*';

            // Post comment
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: comment
            });

            console.log('AI suggestions posted to PR');

      - name: Validate spec language
        run: |
          echo "Validating specification language..."

          # Check for prohibited words in markdown files
          if [ -s changed_md_files.txt ]; then
            while IFS= read -r file; do
              echo "Checking $file for language violations..."
              
              # Check for prohibited words
              prohibited_words=("MUSTN'T" "SHAN'T" "WON'T" "CANNOT" "IMPOSSIBLE")
              violations=()
              
              for word in "${prohibited_words[@]}"; do
                if grep -q -i "$word" "$file"; then
                  violations+=("$word")
                fi
              done
              
              if [ ${#violations[@]} -gt 0 ]; then
                echo "‚ùå Language violations found in $file:"
                printf '  - %s\n' "${violations[@]}"
                exit 1
              else
                echo "‚úÖ No language violations in $file"
              fi
            done < changed_md_files.txt
          fi

      - name: Check for Lean skeletons
        run: |
          echo "Checking for Lean proof skeletons..."

          # Look for .lean files in the diff
          if grep -q "\.lean$" pr_diff.txt; then
            echo "‚úÖ Lean files found in PR"
          else
            echo "‚ö†Ô∏è  No Lean files found - consider adding formal proofs"
          fi

      - name: Update metrics
        run: |
          echo "Updating AI assistant metrics..."

          # Log metrics for tracking
          echo "AI_SPEC_ASSISTANT_RUNS=$(($(date +%s) / 86400))" >> $GITHUB_ENV
          echo "SUGGESTIONS_GENERATED=${#suggestions[@]}" >> $GITHUB_ENV

          # In a real implementation, this would send metrics to a monitoring system
          echo "Metrics logged for tracking"

  spec-linter:
    runs-on: ubuntu-latest
    if: contains(github.event.pull_request.labels.*.name, 'needs-spec-review')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install spectral
        run: |
          npm install -g @stoplight/spectral-cli

      - name: Lint specifications
        run: |
          echo "Linting specifications..."

          # Find all spec files
          find . -name "spec.yaml" -o -name "*.spec.md" | while read spec_file; do
            echo "Linting $spec_file"
            
            # Run spectral lint
            spectral lint "$spec_file" --ruleset aispec-schema.json || {
              echo "‚ùå Specification linting failed for $spec_file"
              exit 1
            }
          done

          echo "‚úÖ All specifications passed linting"

      - name: Check traceability
        run: |
          echo "Checking traceability mappings..."

          # Look for traceability arrows in markdown files
          find . -name "*.md" -exec grep -l "‚Üí" {} \; | while read file; do
            echo "Checking traceability in $file"
            
            # Verify traceability format
            if grep -q "REQ.*‚Üí.*REQ\|NFR.*‚Üí.*NFR" "$file"; then
              echo "‚úÖ Valid traceability found in $file"
            else
              echo "‚ö†Ô∏è  Missing or invalid traceability in $file"
            fi
          done

  weekly-metrics:
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Calculate acceptance rate
        run: |
          echo "Calculating weekly acceptance rate..."

          # This would query a database or metrics system
          # For now, we'll simulate the calculation

          # Simulate metrics collection
          cat > weekly_metrics.json <<EOF
          {
            "week": "$(date +%Y-%W)",
            "total_suggestions": 45,
            "accepted_suggestions": 32,
            "acceptance_rate": 0.71,
            "target_rate": 0.60
          }
          EOF

          # Check if target is met
          acceptance_rate=$(jq -r '.acceptance_rate' weekly_metrics.json)
          target_rate=$(jq -r '.target_rate' weekly_metrics.json)

          if (( $(echo "$acceptance_rate >= $target_rate" | bc -l) )); then
            echo "‚úÖ Acceptance rate $acceptance_rate meets target $target_rate"
          else
            echo "‚ùå Acceptance rate $acceptance_rate below target $target_rate"
            exit 1
          fi

      - name: Generate metrics report
        run: |
          echo "Generating weekly metrics report..."

          cat > ai_spec_metrics_report.md <<EOF
          # AI Spec-Assistant Weekly Metrics Report

          Generated: $(date -u)

          ## Summary

          - **Total Suggestions**: $(jq -r '.total_suggestions' weekly_metrics.json)
          - **Accepted Suggestions**: $(jq -r '.accepted_suggestions' weekly_metrics.json)
          - **Acceptance Rate**: $(jq -r '.acceptance_rate' weekly_metrics.json | sed 's/0\././')
          - **Target Rate**: $(jq -r '.target_rate' weekly_metrics.json | sed 's/0\././')

          ## Performance

          $(if (( $(echo "$(jq -r '.acceptance_rate' weekly_metrics.json) >= $(jq -r '.target_rate' weekly_metrics.json)" | bc -l) )); then
            echo "‚úÖ Target met"
          else
            echo "‚ùå Target not met"
          fi)

          ## Recommendations

          - Continue monitoring suggestion quality
          - Review rejected suggestions for patterns
          - Consider adjusting AI model parameters
          EOF

          echo "Metrics report generated"

      - name: Upload metrics report
        uses: actions/upload-artifact@v4
        with:
          name: ai-spec-metrics
          path: ai_spec_metrics_report.md
          retention-days: 90
