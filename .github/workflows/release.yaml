# SPDX-License-Identifier: Apache-2.0
# Copyright 2025 Provability-Fabric Contributors

name: Release Fence

on:
  push:
    tags:
      - "v*"
  workflow_dispatch:
    inputs:
      version:
        description: "Release version"
        required: true
        default: "v1.0.0"

jobs:
  # Check 1: NI Pass Rate
  ni-fence:
    runs-on: ubuntu-latest
    outputs:
      ni-passed: ${{ steps.check-ni.outputs.passed }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check NI Pass Rate
        id: check-ni
        run: |
          # In production, this would query the ledger for NI verdicts
          # For now, we'll simulate the check
          echo "Checking NI pass rate for last 24h..."

          # Simulate checking 1000 certificates with 100% NI pass rate
          total_certs=1000
          ni_passed=1000
          ni_failed=0

          pass_rate=$(echo "scale=2; $ni_passed / $total_certs" | bc)

          if (( $(echo "$pass_rate >= 1.0" | bc -l) )); then
            echo "✅ NI pass rate: ${pass_rate} (${ni_passed}/${total_certs})"
            echo "passed=true" >> $GITHUB_OUTPUT
          else
            echo "❌ NI pass rate: ${pass_rate} (${ni_passed}/${total_certs})"
            echo "passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi

  # Check 2: SLO Compliance
  slo-fence:
    runs-on: ubuntu-latest
    outputs:
      slo-passed: ${{ steps.check-slo.outputs.passed }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check SLO Compliance
        id: check-slo
        run: |
          # In production, this would query metrics from Prometheus
          # For now, we'll simulate the check
          echo "Checking SLO compliance for last 24h..."

          # Simulate SLO metrics
          p95_latency=1.8
          p99_latency=3.2
          error_rate=0.05

          p95_threshold=2.0
          p99_threshold=4.0
          error_threshold=0.1

          if (( $(echo "$p95_latency <= $p95_threshold" | bc -l) )) && \
             (( $(echo "$p99_latency <= $p99_threshold" | bc -l) )) && \
             (( $(echo "$error_rate <= $error_threshold" | bc -l) )); then
            echo "✅ SLO compliance: p95=${p95_latency}s, p99=${p99_latency}s, error=${error_rate}%"
            echo "passed=true" >> $GITHUB_OUTPUT
          else
            echo "❌ SLO violation detected"
            echo "passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi

  # Check 3: Safety Case Evidence
  evidence-fence:
    runs-on: ubuntu-latest
    outputs:
      evidence-passed: ${{ steps.check-evidence.outputs.passed }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check Safety Case Evidence
        id: check-evidence
        run: |
          # In production, this would check the ledger for safety case completeness
          # For now, we'll simulate the check
          echo "Checking safety case evidence for last 24h..."

          # Simulate checking 1000 sessions for complete evidence
          total_sessions=1000
          complete_sessions=995
          incomplete_sessions=5

          completion_rate=$(echo "scale=2; $complete_sessions / $total_sessions" | bc)

          if (( $(echo "$completion_rate >= 0.99" | bc -l) )); then
            echo "✅ Evidence completeness: ${completion_rate} (${complete_sessions}/${total_sessions})"
            echo "passed=true" >> $GITHUB_OUTPUT
          else
            echo "❌ Evidence incomplete: ${completion_rate} (${complete_sessions}/${total_sessions})"
            echo "passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi

  # Check 4: Security Metrics
  security-fence:
    runs-on: ubuntu-latest
    outputs:
      security-passed: ${{ steps.check-security.outputs.passed }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check Security Metrics
        id: check-security
        run: |
          # In production, this would check injection corpus and ABAC metrics
          # For now, we'll simulate the check
          echo "Checking security metrics for last 24h..."

          # Simulate security metrics
          injection_block_rate=0.97
          abac_violations=0
          pii_detected=0

          injection_threshold=0.95
          abac_threshold=0
          pii_threshold=50000

          if (( $(echo "$injection_block_rate >= $injection_threshold" | bc -l) )) && \
             (( $abac_violations <= $abac_threshold )) && \
             (( $pii_detected <= $pii_threshold )); then
            echo "✅ Security metrics: injection=${injection_block_rate}, abac=${abac_violations}, pii=${pii_detected}"
            echo "passed=true" >> $GITHUB_OUTPUT
          else
            echo "❌ Security violation detected"
            echo "passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi

  # Final Release Decision
  release-decision:
    runs-on: ubuntu-latest
    needs: [ni-fence, slo-fence, evidence-fence, security-fence]
    if: needs.ni-fence.outputs.ni-passed == 'true' &&
      needs.slo-fence.outputs.slo-passed == 'true' &&
      needs.evidence-fence.outputs.evidence-passed == 'true' &&
      needs.security-fence.outputs.security-passed == 'true'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Create Release
        run: |
          echo "🎉 All release fences passed!"
          echo "✅ NI Pass Rate: 100%"
          echo "✅ SLO Compliance: p95<2.0s, p99<4.0s, error<0.1%"
          echo "✅ Evidence Completeness: 99.5%"
          echo "✅ Security Metrics: injection≥95%, abac=0, pii=0"

          # In production, this would create a GitHub release
          # For now, we'll just log the success
          echo "Release approved for deployment"

      - name: Notify Success
        run: |
          echo "Release fence checks completed successfully"
          echo "All critical metrics within acceptable ranges"
          echo "System ready for production deployment"

  # Failure Notification
  release-failed:
    runs-on: ubuntu-latest
    needs: [ni-fence, slo-fence, evidence-fence, security-fence]
    if: failure() && (needs.ni-fence.outputs.ni-passed == 'false' ||
      needs.slo-fence.outputs.slo-passed == 'false' ||
      needs.evidence-fence.outputs.evidence-passed == 'false' ||
      needs.security-fence.outputs.security-passed == 'false')
    steps:
      - name: Notify Failure
        run: |
          echo "❌ Release blocked by fence violations:"

          if [ "${{ needs.ni-fence.outputs.ni-passed }}" = "false" ]; then
            echo "  - NI pass rate below 100%"
          fi

          if [ "${{ needs.slo-fence.outputs.slo-passed }}" = "false" ]; then
            echo "  - SLO violations detected"
          fi

          if [ "${{ needs.evidence-fence.outputs.evidence-passed }}" = "false" ]; then
            echo "  - Evidence completeness below 99%"
          fi

          if [ "${{ needs.security-fence.outputs.security-passed }}" = "false" ]; then
            echo "  - Security metric violations"
          fi

          echo "Release cannot proceed until all fences pass"
          exit 1
