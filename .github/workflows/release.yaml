# SPDX-License-Identifier: Apache-2.0
# Copyright 2025 Provability-Fabric Contributors

name: Release Fence

on:
  push:
    tags:
      - "v*"
  workflow_dispatch:
    inputs:
      version:
        description: "Release version"
        required: true
        default: "v1.0.0"
      simulate_bad_release:
        description: "Simulate bad release for testing"
        required: false
        default: false
        type: boolean

jobs:
  # Check 1: NI Pass Rate
  ni-fence:
    runs-on: ubuntu-latest
    outputs:
      ni-passed: ${{ steps.check-ni.outputs.passed }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check NI Pass Rate
        id: check-ni
        run: |
          # In production, this would query the ledger for NI verdicts
          # For now, we'll simulate the check
          echo "Checking NI pass rate for last 24h..."

          # Simulate checking 1000 certificates with 100% NI pass rate
          total_certs=1000
          ni_passed=1000
          ni_failed=0

          pass_rate=$(echo "scale=2; $ni_passed / $total_certs" | bc)

          if (( $(echo "$pass_rate >= 1.0" | bc -l) )); then
            echo "âœ… NI pass rate: ${pass_rate} (${ni_passed}/${total_certs})"
            echo "passed=true" >> $GITHUB_OUTPUT
          else
            echo "âŒ NI pass rate: ${pass_rate} (${ni_passed}/${total_certs})"
            echo "passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi

  # Check 2: SLO Compliance
  slo-fence:
    runs-on: ubuntu-latest
    outputs:
      slo-passed: ${{ steps.check-slo.outputs.passed }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check SLO Compliance
        id: check-slo
        run: |
          # In production, this would query metrics from Prometheus
          # For now, we'll simulate the check
          echo "Checking SLO compliance for last 24h..."

          # Simulate SLO metrics
          p95_latency=1.8
          p99_latency=3.2
          error_rate=0.05

          p95_threshold=2.0
          p99_threshold=4.0
          error_threshold=0.1

          if (( $(echo "$p95_latency <= $p95_threshold" | bc -l) )) && \
             (( $(echo "$p99_latency <= $p99_threshold" | bc -l) )) && \
             (( $(echo "$error_rate <= $error_threshold" | bc -l) )); then
            echo "âœ… SLO compliance: p95=${p95_latency}s, p99=${p99_latency}s, error=${error_rate}%"
            echo "passed=true" >> $GITHUB_OUTPUT
          else
            echo "âŒ SLO violation detected"
            echo "passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi

  # Check 3: Safety Case Evidence
  evidence-fence:
    runs-on: ubuntu-latest
    outputs:
      evidence-passed: ${{ steps.check-evidence.outputs.passed }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check Safety Case Evidence
        id: check-evidence
        run: |
          # In production, this would check the ledger for safety case completeness
          # For now, we'll simulate the check
          echo "Checking safety case evidence for last 24h..."

          # Simulate checking 1000 sessions for complete evidence
          total_sessions=1000
          complete_sessions=995
          incomplete_sessions=5

          completion_rate=$(echo "scale=2; $complete_sessions / $total_sessions" | bc)

          if (( $(echo "$completion_rate >= 0.99" | bc -l) )); then
            echo "âœ… Evidence completeness: ${completion_rate} (${complete_sessions}/${total_sessions})"
            echo "passed=true" >> $GITHUB_OUTPUT
          else
            echo "âŒ Evidence incomplete: ${completion_rate} (${complete_sessions}/${total_sessions})"
            echo "passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi

  # Check 4: Security Metrics
  security-fence:
    runs-on: ubuntu-latest
    outputs:
      security-passed: ${{ steps.check-security.outputs.passed }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check Security Metrics
        id: check-security
        run: |
          # In production, this would check injection corpus and ABAC metrics
          # For now, we'll simulate the check
          echo "Checking security metrics for last 24h..."

          # Simulate security metrics
          injection_block_rate=0.97
          abac_violations=0
          pii_detected=0

          injection_threshold=0.95
          abac_threshold=0
          pii_threshold=50000

          if (( $(echo "$injection_block_rate >= $injection_threshold" | bc -l) )) && \
             (( $abac_violations <= $abac_threshold )) && \
             (( $pii_detected <= $pii_threshold )); then
            echo "âœ… Security metrics: injection=${injection_block_rate}, abac=${abac_violations}, pii=${pii_detected}"
            echo "passed=true" >> $GITHUB_OUTPUT
          else
            echo "âŒ Security violation detected"
            echo "passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi

  # Final Release Decision
  release-decision:
    runs-on: ubuntu-latest
    needs: [ni-fence, slo-fence, evidence-fence, security-fence]
    if: needs.ni-fence.outputs.ni-passed == 'true' &&
      needs.slo-fence.outputs.slo-passed == 'true' &&
      needs.evidence-fence.outputs.evidence-passed == 'true' &&
      needs.security-fence.outputs.security-passed == 'true'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Create Release
        run: |
          echo "ðŸŽ‰ All release fences passed!"
          echo "âœ… NI Pass Rate: 100%"
          echo "âœ… SLO Compliance: p95<2.0s, p99<4.0s, error<0.1%"
          echo "âœ… Evidence Completeness: 99.5%"
          echo "âœ… Security Metrics: injectionâ‰¥95%, abac=0, pii=0"

          # In production, this would create a GitHub release
          # For now, we'll just log the success
          echo "Release approved for deployment"

      - name: Notify Success
        run: |
          echo "Release fence checks completed successfully"
          echo "All critical metrics within acceptable ranges"
          echo "System ready for production deployment"

      - name: Trigger pf-testbed Testing
        run: |
          echo "ðŸš€ Triggering pf-testbed testing for release ${{ github.ref_name }}"
          
          # Extract version from tag (remove 'v' prefix)
          VERSION=${GITHUB_REF#refs/tags/}
          VERSION=${VERSION#v}
          
          echo "Testing version: $VERSION"
          
          # Send repository dispatch to pf-testbed
          curl -X POST \
            -H "Accept: application/vnd.github.v3+json" \
            -H "Authorization: token ${{ secrets.CI_PAT }}" \
            -H "X-GitHub-Api-Version: 2022-11-28" \
            https://api.github.com/repos/provability-fabric/pf-testbed/dispatches \
            -d '{
              "event_type": "on-core-release",
              "client_payload": {
                "version": "'$VERSION'",
                "core_repo": "'$GITHUB_REPOSITORY'",
                "release_url": "'$GITHUB_SERVER_URL'/$GITHUB_REPOSITORY/releases/tag/$GITHUB_REF_NAME'",
                "commit_sha": "'$GITHUB_SHA'",
                "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"
              }
            }'
          
          echo "âœ… Repository dispatch sent to pf-testbed"
          echo "Event: on-core-release"
          echo "Version: $VERSION"

      - name: Wait for pf-testbed Results
        run: |
          echo "â³ Waiting for pf-testbed test results..."
          echo "This step would poll pf-testbed status in production"
          
          # In production, this would:
          # 1. Poll pf-testbed status endpoint
          # 2. Wait for test completion
          # 3. Fail if tests fail
          # 4. Continue if tests pass
          
          echo "âœ… pf-testbed testing completed successfully"

  # Failure Notification
  release-failed:
    runs-on: ubuntu-latest
    needs: [ni-fence, slo-fence, evidence-fence, security-fence]
    if: failure() && (needs.ni-fence.outputs.ni-passed == 'false' ||
      needs.slo-fence.outputs.slo-passed == 'false' ||
      needs.evidence-fence.outputs.evidence-passed == 'false' ||
      needs.security-fence.outputs.security-passed == 'false')

    steps:
      - name: Notify Failure
        run: |
          echo "âŒ Release blocked by fence violations:"

          if [ "${{ needs.ni-fence.outputs.ni-passed }}" = "false" ]; then
            echo "  - NI pass rate below 100%"
          fi

          if [ "${{ needs.slo-fence.outputs.slo-passed }}" = "false" ]; then
            echo "  - SLO violations detected"
          fi

          if [ "${{ needs.evidence-fence.outputs.evidence-passed }}" = "false" ]; then
            echo "  - Evidence completeness below 99%"
          fi

          if [ "${{ needs.security-fence.outputs.security-passed }}" = "false" ]; then
            echo "  - Security metric violations"
          fi

          echo "Release cannot proceed until all fences pass"
          exit 1

  # Testbed Failure Simulation (for testing)
  testbed-failure-simulation:
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.simulate_bad_release == 'true' }}
    steps:
      - name: Simulate Bad Release
        run: |
          echo "ðŸ§ª Simulating bad release scenario..."
          echo "This would trigger pf-testbed CI failure in production"
          
          # Simulate pf-testbed test failure
          echo "âŒ pf-testbed tests failed"
          echo "Core release job should fail"
          
          # Exit with failure to simulate bad release
          exit 1

          if [ "${{ needs.ni-fence.outputs.ni-passed }}" = "false" ]; then
            echo "  - NI pass rate below 100%"
          fi

          if [ "${{ needs.slo-fence.outputs.slo-passed }}" = "false" ]; then
            echo "  - SLO violations detected"
          fi

          if [ "${{ needs.evidence-fence.outputs.evidence-passed }}" = "false" ]; then
            echo "  - Evidence completeness below 99%"
          fi

          if [ "${{ needs.security-fence.outputs.security-passed }}" = "false" ]; then
            echo "  - Security metric violations"
          fi

          echo "Release cannot proceed until all fences pass"
          exit 1
